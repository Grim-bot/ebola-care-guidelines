{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook validates the IMC models on the KGH (Kenema) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy import interp\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogRegModel(object):\n",
    "    def __init__(self, fn, model_format='MICE'):\n",
    "        self.intercept = 0\n",
    "        self.names = []        \n",
    "        self.terms = []\n",
    "        if model_format == 'MICE':\n",
    "            self.loadTermsMICE(fn)\n",
    "        elif model_format == 'GLM':\n",
    "            self.loadTermsGLM(fn)\n",
    "            \n",
    "    def setIntercept(self, b0):\n",
    "        self.intercept = b0\n",
    "\n",
    "    def addTerm(self, t):\n",
    "        self.terms += [t]\n",
    "        self.names += [t.name]        \n",
    "\n",
    "    def linfeat(self, x):\n",
    "        zmat = []\n",
    "        for i in range(0, len(x)):\n",
    "            xrow = x[i]\n",
    "            zrow = [1.0]\n",
    "            for j in range(0, len(self.terms)):\n",
    "                t = self.terms[j]\n",
    "                zrow += t.linearFeatures(xrow[j])\n",
    "            zmat += [zrow]\n",
    "        return zmat\n",
    "\n",
    "    def lincoeff(self):\n",
    "        coeff = [self.intercept]\n",
    "        for t in self.terms:\n",
    "            coeff += t.coeffs\n",
    "        return coeff    \n",
    "                \n",
    "    def sigmoid(self, v):\n",
    "        return 1.0 / (1.0 + np.exp(-v))\n",
    "            \n",
    "    def predict(self, x):\n",
    "        z = self.linfeat(x)\n",
    "        theta = self.lincoeff()\n",
    "        prob = []\n",
    "        n = len(z)\n",
    "        for i in range(0, n):            \n",
    "            p = self.sigmoid(np.dot(z[i], theta))\n",
    "            prob += [p]\n",
    "        return np.array(prob)\n",
    "\n",
    "    def loatVarTypes(self, data_fn, dict_fn):\n",
    "        var = []\n",
    "        vtyp= []\n",
    "        with open(data_fn) as f:\n",
    "            var = f.readlines()[0].split(',')\n",
    "        with open(dict_fn) as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                if not line: continue\n",
    "                _, t = line.split(',')[0:2]\n",
    "                vtyp += [t]\n",
    "        for t in self.terms:\n",
    "            pos = var.index(t.name)\n",
    "            t.vtyp = vtyp[pos]\n",
    "            \n",
    "    def saveOddRatios(self, x, fn):\n",
    "        theta = self.lincoeff()\n",
    "        scale = [1.0] * len(theta)\n",
    "\n",
    "        t = 0\n",
    "        ts = 1\n",
    "        for term in self.terms:\n",
    "            vrang = term.varRanges(x[:,t]) \n",
    "            for i in range(0, len(vrang)):\n",
    "                scale[ts] = vrang[i]\n",
    "                if scale[ts] < 1: scale[ts] = 1.0 / scale[ts]\n",
    "                ts = ts + 1                \n",
    "            t = t + 1\n",
    "\n",
    "        theta *= np.array(scale)\n",
    "        odds = np.exp(theta)\n",
    "        ts = 1\n",
    "        with open(fn, 'w') as f:                \n",
    "            for term in self.terms:\n",
    "                vnam = term.varNames()\n",
    "                for i in range(0, len(vnam)):\n",
    "                    f.write(vnam[i] + ' ' + str(odds[ts]) + '\\n')\n",
    "                    ts = ts + 1\n",
    "                    \n",
    "    def getFormula(self, digits):\n",
    "        formula = str(round(self.intercept, digits))\n",
    "        for term in self.terms:\n",
    "            formula = formula + term.getFormula(digits)\n",
    "        return formula\n",
    "        \n",
    "    def saveRanges(self, x, fn):\n",
    "        nrows = len(x)\n",
    "        nvars = len(self.terms)\n",
    "        values = np.zeros((nrows, nvars))\n",
    "        for i in range(0, nrows):\n",
    "            xrow = x[i]\n",
    "            vrow = values[i]\n",
    "            for t in range(0, len(self.terms)):\n",
    "                term = self.terms[t]\n",
    "                vrow[t] = term.value(xrow[t])\n",
    "\n",
    "        with open(fn, 'w') as f:                \n",
    "            for t in range(0, len(self.terms)):\n",
    "                term = self.terms[t]\n",
    "                mint = min(values[:,t])\n",
    "                maxt = max(values[:,t])\n",
    "                f.write(term.name + ' ' + str(mint) + ' ' + str(maxt) + '\\n')            \n",
    "\n",
    "    def saveRCSTerms(self, x, d):\n",
    "        for t in range(0, len(self.terms)):            \n",
    "            term = self.terms[t]\n",
    "            if not term.isRCS: continue\n",
    "            yvalues = []\n",
    "            xmin = x[:,t].min()\n",
    "            xmax = x[:,t].max()                \n",
    "            xvalues = np.linspace(xmin, xmax, 100)\n",
    "            for xt in xvalues:\n",
    "                y = term.value(xt)\n",
    "                yvalues += [y]\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.plot(xvalues, yvalues)\n",
    "            plt.xlabel(term.name, labelpad=20)\n",
    "            plt.title('RCS term for ' + term.name)\n",
    "            fig.savefig(os.path.join(d, 'rcs_' + term.name + '.pdf'))\n",
    "                \n",
    "    def loadTermsMICE(self, fn):\n",
    "        rcsCoeffs = None;\n",
    "        lines = []\n",
    "        with open(fn) as ifn:    \n",
    "            lines = ifn.readlines()\n",
    "\n",
    "        pos = lines[0].index('est') + 2\n",
    "\n",
    "        n = 1;\n",
    "        while n < len(lines):\n",
    "            line = lines[n]     \n",
    "            n += 1\n",
    "            \n",
    "            s = line[0:pos].strip()\n",
    "            \n",
    "            v = s.split()\n",
    "            if line[0] == ' ' or len(v) == 1: break\n",
    "            valueStr = v[-1]\n",
    "            value = float(valueStr)\n",
    "\n",
    "            pos0 = s.index(valueStr)\n",
    "            var = s[0:pos0].strip()\n",
    "\n",
    "            if 'rcs' in var and var.index('rcs') == 0:\n",
    "                pos1 = var.rfind(')')\n",
    "                rcsString = var[4:pos1]\n",
    "                pieces = rcsString.split('c')\n",
    "                part1 = pieces[0].split(',')\n",
    "                varName = part1[0].strip()\n",
    "                rcsOrder = int(part1[1].strip())\n",
    "                knotStr = pieces[1].replace(\"(\", \"\").replace(\")\", \"\").split(\",\")\n",
    "                rcsKnots = [float(k) for k in knotStr]\n",
    "                coeffOrder = len(var) - len(var.replace(\"'\", \"\"))\n",
    "                \n",
    "                if coeffOrder == 0:\n",
    "                    rcsCoeffs = [0.0] * (rcsOrder - 1);\n",
    "                if rcsCoeffs: \n",
    "                    rcsCoeffs[coeffOrder] = value;\n",
    "\n",
    "                if coeffOrder == rcsOrder - 2:\n",
    "                    term = RCSTerm(varName, rcsOrder, rcsCoeffs, rcsKnots)\n",
    "                    self.addTerm(term)              \n",
    "            else:\n",
    "                if var == '(Intercept)':\n",
    "                    self.setIntercept(value);\n",
    "                else:\n",
    "                    term = LinearTerm(var, value)\n",
    "                    self.addTerm(term)\n",
    "\n",
    "    def loadTermsGLM(self, fn):               \n",
    "        rcsCoeffs = None;\n",
    "        lines = []\n",
    "        with open(fn) as ifn:    \n",
    "            lines = ifn.readlines()\n",
    "\n",
    "        reading = False\n",
    "        n = 1;\n",
    "        while n < len(lines):\n",
    "            line = lines[n]\n",
    "            n += 1\n",
    "\n",
    "            if '(Intercept)' in line: \n",
    "                reading = True\n",
    "                val = line.split()[1]\n",
    "                pos = line.index(val) + len(val)\n",
    "                \n",
    "                # This breaks easily if file is not properly formatted:\n",
    "                #pos = line.index('Estimate') + 8\n",
    "                #continue\n",
    "            \n",
    "            if not reading: continue\n",
    "            \n",
    "            s = line[0:pos].strip()\n",
    "            \n",
    "            v = s.split()\n",
    "            if line[0] == ' ' or len(v) == 1 or v[0] == '---': break   \n",
    "            valueStr = v[-1]\n",
    "            value = float(valueStr)\n",
    "\n",
    "            pos0 = s.index(valueStr)\n",
    "            var = s[0:pos0].strip()\n",
    "\n",
    "            if 'rcs' in var and var.index('rcs') == 0:\n",
    "                pos1 = var.rfind(')')\n",
    "                rcsString = var[4:pos1]\n",
    "                pieces = rcsString.split('c')\n",
    "                part1 = pieces[0].split(',')\n",
    "                varName = part1[0].strip()\n",
    "                rcsOrder = int(part1[1].strip())\n",
    "                knotStr = pieces[1].replace(\"(\", \"\").replace(\")\", \"\").split(\",\")\n",
    "                rcsKnots = [float(k) for k in knotStr]\n",
    "                coeffOrder = len(var) - len(var.replace(\"'\", \"\"))\n",
    "                \n",
    "                if coeffOrder == 0:\n",
    "                    rcsCoeffs = [0.0] * (rcsOrder - 1);\n",
    "                if rcsCoeffs: \n",
    "                    rcsCoeffs[coeffOrder] = value;\n",
    "\n",
    "                if coeffOrder == rcsOrder - 2:\n",
    "                    term = RCSTerm(varName, rcsOrder, rcsCoeffs, rcsKnots)\n",
    "                    self.addTerm(term)              \n",
    "            else:\n",
    "                if var == '(Intercept)':\n",
    "                    self.setIntercept(value);\n",
    "                else:\n",
    "                    term = LinearTerm(var, value)\n",
    "                    self.addTerm(term)\n",
    "                    \n",
    "class ModelTerm(object):\n",
    "    def __init__(self, name):\n",
    "        self.isRCS = False\n",
    "        self.name = name\n",
    "        self.vtyp = 'float'\n",
    "        self.coeffs = []\n",
    "    def linearFeatures(self, x):\n",
    "        return [0.0] * len(self.coeffs)\n",
    "    def varRanges(self, x):\n",
    "        # Scale coefficients by IQR (in floating-point variables) or\n",
    "        # closest power-of-ten for integer variables.        \n",
    "        if self.vtyp == 'category': \n",
    "            return [1]\n",
    "        elif self.vtyp == 'int':\n",
    "            n = np.floor(np.log10(max(x)))\n",
    "            return [np.power(10, n)]\n",
    "        elif self.vtyp == 'float':                                \n",
    "            return [np.percentile(x, 75) - np.percentile(x, 25)]\n",
    "    def getFormula(self, digits):\n",
    "        return ''\n",
    "    def varNames(self):\n",
    "        return [self.name]\n",
    "    def value(self, x): \n",
    "        return np.dot(self.coeffs, self.linearFeatures(x))\n",
    "    \n",
    "class LinearTerm(ModelTerm):\n",
    "    def __init__(self, name, c):\n",
    "        ModelTerm.__init__(self, name)\n",
    "        self.coeffs = [c]\n",
    "\n",
    "    def linearFeatures(self, x):\n",
    "        return [x]\n",
    "\n",
    "    def getFormula(self, digits):\n",
    "        c = self.coeffs[0]\n",
    "        sign = ' + ' if 0 < c else ' - '\n",
    "        return sign + str(round(abs(c), digits)) + ' ' + self.name\n",
    "    \n",
    "    def __str__(self):\n",
    "        res = \"Linear term for \" + self.name + \"\\n\"\n",
    "        res += \"  Coefficient: \" + str(self.coeffs[0])\n",
    "        return res\n",
    "\n",
    "class RCSTerm(ModelTerm):\n",
    "    def __init__(self, name, k, c, kn):\n",
    "        ModelTerm.__init__(self, name)\n",
    "        self.isRCS = True        \n",
    "        self.order = k\n",
    "        self.coeffs = list(c)\n",
    "        self.knots = list(kn)\n",
    "\n",
    "    def cubic(self, u):\n",
    "        t = np.maximum(0, u)\n",
    "        return t * t * t\n",
    "    \n",
    "    def rcs(self, x, term):\n",
    "        k = len(self.knots) - 1\n",
    "        j = term - 1\n",
    "        t = self.knots\n",
    "        c = (t[k] - t[0]) * (t[k] - t[0])\n",
    "        value = +self.cubic(x - t[j]) \\\n",
    "                -self.cubic(x - t[k - 1]) * (t[k] - t[j])/(t[k] - t[k-1]) \\\n",
    "                +self.cubic(x - t[k]) * (t[k - 1] - t[j])/(t[k] - t[k-1]) \n",
    "        return value / c\n",
    "    \n",
    "    def rcsform(self, term, digits):\n",
    "        k = len(self.knots) - 1\n",
    "        j = term - 1\n",
    "        t = self.knots\n",
    "        c = (t[k] - t[0]) * (t[k] - t[0])\n",
    "          \n",
    "        c0 = self.coeffs[term] / c\n",
    "        sign0 = ' + ' if 0 < c0 else ' - '\n",
    "        s = sign0 + str(round(abs(c0), digits[0])) + ' max(%s - ' + str(round(t[j], 3)) + ', 0)^3' \n",
    "    \n",
    "        c1 = self.coeffs[term] * (t[k] - t[j])/(c * (t[k] - t[k-1]))    \n",
    "        sign1 = ' - ' if 0 < c1 else ' + '\n",
    "        s += sign1 + str(round(abs(c1), digits[1])) + ' max(%s - ' + str(round(t[k - 1], 3)) + ', 0)^3' \n",
    "    \n",
    "        c2 = self.coeffs[term] * (t[k - 1] - t[j])/(c * (t[k] - t[k-1]))\n",
    "        sign2 = ' + ' if 0 < c2 else ' - '        \n",
    "        s += sign2 + str(round(c2, digits[2])) + ' max(%s - ' + str(round(t[k], 3)) + ', 0)^3' \n",
    "    \n",
    "        return s\n",
    "\n",
    "    def linearFeatures(self, x):\n",
    "        feat = [0.0] * (self.order - 1)\n",
    "        feat[0] = x\n",
    "        for t in range(1, self.order - 1):\n",
    "            feat[t] = self.rcs(x, t)\n",
    "        return feat           \n",
    "\n",
    "    def varRanges(self, x):\n",
    "        rang = [0.0] * (self.order - 1)\n",
    "        rang[0] = np.percentile(x, 75) - np.percentile(x, 25)\n",
    "        for i in range(1, self.order - 1):\n",
    "            y = self.rcs(x, i)\n",
    "            rang[i] = np.percentile(y, 75) - np.percentile(y, 25)            \n",
    "        return rang\n",
    "    \n",
    "    def varNames(self):\n",
    "        nam = [''] * (self.order - 1)\n",
    "        nam[0] = self.name\n",
    "        for i in range(1, self.order - 1):\n",
    "            nam[i] = self.name + (\"'\" * i)\n",
    "        return nam\n",
    "    \n",
    "    def getFormula(self, digits):        \n",
    "        c = self.coeffs[0]\n",
    "        sign = ' + ' if 0 < c else ' - '\n",
    "        s = sign + str(round(abs(c), digits)) + ' ' + self.name\n",
    "        for i in range(1, self.order - 1):\n",
    "            s = s + self.rcsform(i, [digits] * 3) % (self.name, self.name, self.name)\n",
    "        return s\n",
    "    \n",
    "    def __str__(self):\n",
    "        res = \"RCS term of order \" + str(self.order) + \" for \" + self.name + \"\\n\"\n",
    "        res += \"  Coefficients:\";\n",
    "        for i in range(0, len(self.coeffs)):\n",
    "            res += \" \" + str(self.coeffs[i])\n",
    "        res += \"\\n\"\n",
    "        res += \"  Knots:\"\n",
    "        for i in range(0, len(self.knots)):\n",
    "            res += \" \" + str(self.knots[i])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Measurements inspired by Philip Tetlock's \"Expert Political Judgment\"\n",
    "Equations take from Yaniv, Yates, & Smith (1991):\n",
    "  \"Measures of Descrimination Skill in Probabilistic Judgement\"\n",
    "\"\"\"\n",
    "\n",
    "def calibration(outcome, prob, n_bins=10):\n",
    "    \"\"\"Calibration measurement for a set of predictions.\n",
    "    When predicting events at a given probability, how far is frequency\n",
    "    of positive outcomes from that probability?\n",
    "    NOTE: Lower scores are better\n",
    "    prob: array_like, float\n",
    "        Probability estimates for a set of events\n",
    "    outcome: array_like, bool\n",
    "        If event predicted occurred\n",
    "    n_bins: int\n",
    "        Number of judgement categories to prefrom calculation over.\n",
    "        Prediction are binned based on probability, since \"discrete\" \n",
    "        probabilities aren't required. \n",
    "    \"\"\"\n",
    "    prob = np.array(prob)\n",
    "    outcome = np.array(outcome)\n",
    "\n",
    "    c = 0.0\n",
    "    # Construct bins\n",
    "    judgement_bins = np.arange(n_bins + 1.0) / n_bins\n",
    "    # Which bin is each prediction in?\n",
    "    bin_num = np.digitize(prob,judgement_bins)\n",
    "    for j_bin in np.unique(bin_num):\n",
    "        # Is event in bin\n",
    "        in_bin = bin_num == j_bin\n",
    "        # Predicted probability taken as average of preds in bin\n",
    "        predicted_prob = np.mean(prob[in_bin])\n",
    "        # How often did events in this bin actually happen?\n",
    "        true_bin_prob = np.mean(outcome[in_bin])\n",
    "        # Squared distance between predicted and true times num of obs\n",
    "        c += np.sum(in_bin) * ((predicted_prob - true_bin_prob) ** 2)\n",
    "    return c / len(prob)\n",
    "\n",
    "\n",
    "def calibration_table(outcome, prob, n_bins=10):\n",
    "    \"\"\"Calibration measurement for a set of predictions.\n",
    "    When predicting events at a given probability, how far is frequency\n",
    "    of positive outcomes from that probability?\n",
    "    NOTE: Lower scores are better\n",
    "    prob: array_like, float\n",
    "        Probability estimates for a set of events\n",
    "    outcome: array_like, bool\n",
    "        If event predicted occurred\n",
    "    n_bins: int\n",
    "        Number of judgement categories to prefrom calculation over.\n",
    "        Prediction are binned based on probability, since \"discrete\" \n",
    "        probabilities aren't required. \n",
    "    \"\"\"\n",
    "    prob = np.array(prob)\n",
    "    outcome = np.array(outcome)\n",
    "\n",
    "    c = 0.0\n",
    "    # Construct bins\n",
    "    judgement_bins = np.arange(n_bins + 1.0) / n_bins\n",
    "    # Which bin is each prediction in?\n",
    "    bin_num = np.digitize(prob, judgement_bins)\n",
    "\n",
    "    counts = []\n",
    "    true_prob = []\n",
    "    pred_prob = []\n",
    "    for j_bin in np.arange(n_bins + 1):\n",
    "        # Is event in bin\n",
    "        in_bin = bin_num == j_bin\n",
    "#         # Predicted probability taken as average of preds in bin        \n",
    "        predicted_prob = np.mean(prob[in_bin])\n",
    "#         # How often did events in this bin actually happen?\n",
    "        true_bin_prob = np.mean(outcome[in_bin])\n",
    "        counts.append(np.sum(0 <= prob[in_bin]))\n",
    "        true_prob.append(true_bin_prob) \n",
    "        pred_prob.append(predicted_prob)\n",
    "    \n",
    "    cal_table = pd.DataFrame({'pred_prob':pd.Series(np.array(pred_prob)), \n",
    "                              'count':pd.Series(np.array(counts)),\n",
    "                              'true_prob':pd.Series(np.array(true_prob))}, \n",
    "                              columns=['pred_prob', 'count', 'true_prob'])\n",
    "    cal_table.dropna(inplace=True)\n",
    "    return cal_table \n",
    "\n",
    "\n",
    "def discrimination(outcome, prob, n_bins=10):\n",
    "    \"\"\"Discrimination measurement for a set of predictions.\n",
    "    For each judgement category, how far from the base probability\n",
    "    is the true frequency of that bin?\n",
    "    NOTE: High scores are better\n",
    "    prob: array_like, float\n",
    "        Probability estimates for a set of events\n",
    "    outcome: array_like, bool\n",
    "        If event predicted occurred\n",
    "    n_bins: int\n",
    "        Number of judgement categories to prefrom calculation over.\n",
    "        Prediction are binned based on probability, since \"discrete\" \n",
    "        probabilities aren't required. \n",
    "    \"\"\"\n",
    "    prob = np.array(prob)\n",
    "    outcome = np.array(outcome)\n",
    "\n",
    "    d = 0.0\n",
    "    # Base frequency of outcomes\n",
    "    base_prob = np.mean(outcome)\n",
    "    # Construct bins\n",
    "    judgement_bins = np.arange(n_bins + 1.0) / n_bins\n",
    "    # Which bin is each prediction in?\n",
    "    bin_num = np.digitize(prob,judgement_bins)\n",
    "    for j_bin in np.unique(bin_num):\n",
    "        in_bin = bin_num == j_bin\n",
    "        true_bin_prob = np.mean(outcome[in_bin])\n",
    "        # Squared distance between true and base times num of obs\n",
    "        d += np.sum(in_bin) * ((true_bin_prob - base_prob) ** 2)\n",
    "    return d / len(prob)\n",
    "\n",
    "def caldis(outcome, probs, n_bins=10):\n",
    "    c = calibration(outcome, probs, n_bins)\n",
    "    d = discrimination(outcome, probs, n_bins)\n",
    "    return c, d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel_model = 1\n",
    "\n",
    "if sel_model == 1:\n",
    "    model_name = 'min'\n",
    "if sel_model == 2:\n",
    "    model_name = 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load IMC and Kenema data\n",
    "imc_data_file = '../data/data.csv'\n",
    "kenema_data_file = '../data/kenema/data.csv'\n",
    "\n",
    "imc_data = pd.read_csv(imc_data_file, na_values=\"\\\\N\")\n",
    "kenema_data = pd.read_csv(kenema_data_file, na_values=\"\\\\N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute transformation between viral load and CT:\n",
    "\n",
    "min_ct = imc_data['cycletime'].min()\n",
    "max_ct = imc_data['cycletime'].max()\n",
    "min_log_pcr = kenema_data['PCR'].min()\n",
    "max_log_pcr = kenema_data['PCR'].max()\n",
    "print min_ct, max_log_pcr\n",
    "print max_ct, min_log_pcr\n",
    "b = (max_log_pcr - min_log_pcr) / (max_ct - min_ct)\n",
    "a = min_log_pcr + b * max_ct\n",
    "vl2ct_c1 = -1/b\n",
    "vl2ct_c0 = +a/b\n",
    "print 3*b\n",
    "print vl2ct_c1, vl2ct_c0\n",
    "\n",
    "# Compare with:\n",
    "# Each 3-point decrease in Ct was associated with an ≈10-fold increase in Ebola viral load; \n",
    "# a Ct of 39 corresponded to ≈40 TCID50/mL and a Ct of 19 corresponded to ≈40 million TCID50/mL\n",
    "# http://www.fda.gov/downloads/medicaldevices/safety/emergencysituations/ucm436313.pdf\n",
    "# Based on this, 3*b should be close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate datasets\n",
    "test_data_folder = '../data/kenema/test'\n",
    "test_data_file = '../data/kenema/test/all_data.csv'\n",
    "if not os.path.exists(test_data_folder):\n",
    "    os.makedirs(test_data_folder)\n",
    "    \n",
    "# Load imputation files for selected model, if any\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists    \n",
    "imp_data_folder = os.path.join(test_data_folder, model_name)\n",
    "if not os.path.exists(imp_data_folder):\n",
    "    os.makedirs(imp_data_folder)\n",
    "imp_data_files = [join(imp_data_folder, f) for f in listdir(imp_data_folder) if isfile(join(imp_data_folder, f))]\n",
    "\n",
    "if sel_model == 1:\n",
    "    src_variables = ['OUT', 'PCR', 'AGE']\n",
    "    variables = ['OUT', 'CT', 'AGE']\n",
    "elif sel_model == 3:\n",
    "    src_variables = ['OUT', 'PCR', 'AGE', 'DIARR', 'WEAK', 'JAUN', 'BNONE', 'TEMP', 'HEADCH', 'VOMIT', 'PABD']\n",
    "    variables = ['OUT', 'CT', 'AGE', 'TEMP', 'HEADCH', 'BLEED', 'DIARR', 'JAUN', 'VOMIT', 'PABD', 'WEAK']\n",
    "    \n",
    "test_data = kenema_data[kenema_data['DIAG'] == 1][src_variables]\n",
    "\n",
    "test_data['CT'] = vl2ct_c1 * test_data['PCR'] + vl2ct_c0\n",
    "\n",
    "if 'SEX' in variables and 'GEND' in src_variables:\n",
    "    test_data['SEX'] = 1 - test_data['GEND']\n",
    "if 'BLEED' in variables and 'BNONE' in src_variables:\n",
    "    test_data['BLEED'] = 1 - test_data['BNONE']\n",
    "if 'JAUN' in variables:\n",
    "    test_data['JAUN'] = 0 # all the non-missing values are 0, so MICE won't impute it\n",
    "\n",
    "test_data = test_data[variables]\n",
    "test_data.to_csv(test_data_file, index=False, na_rep=\"\\\\N\")\n",
    "\n",
    "test_data['OUT']\n",
    "\n",
    "complete_data = test_data.dropna()\n",
    "complete_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_params = os.path.join(model_name, 'mice.txt')\n",
    "model = LogRegModel(model_params)\n",
    "\n",
    "x = complete_data[complete_data.columns[1:]].values\n",
    "ytrue = [int(v) for v in complete_data[complete_data.columns[0]].values]\n",
    "probs = model.predict(x)\n",
    "ypred = [int(0.5 < p) for p in probs]\n",
    "\n",
    "auc = roc_auc_score(ytrue, probs)\n",
    "fpr, tpr, thresholds = roc_curve(ytrue, probs) \n",
    "brier = brier_score_loss(ytrue, probs)\n",
    "cal, dis = caldis(ytrue, probs)\n",
    "acc = accuracy_score(ytrue, ypred)\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(ytrue, ypred)\n",
    "\n",
    "P = N = 0\n",
    "TP = TN = 0\n",
    "FP = FN = 0\n",
    "for i in range(len(ytrue)):\n",
    "    if ytrue[i] == 1:\n",
    "        P += 1\n",
    "        if ypred[i] == 1: TP += 1\n",
    "        else: FN += 1\n",
    "    else:\n",
    "        N += 1\n",
    "        if ypred[i] == 0: TN += 1\n",
    "        else: FP += 1\n",
    "            \n",
    "sens = float(TP)/P\n",
    "spec = float(TN)/N\n",
    "\n",
    "# Positive and Negative Predictive Values\n",
    "# https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values\n",
    "ppv = float(TP) / (TP + FP)\n",
    "npv = float(TN) / (TN + FN)\n",
    "        \n",
    "# Likelihood ratios\n",
    "# https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing\n",
    "lr_pos = sens / (1 - spec) if spec < 1 else np.inf\n",
    "lr_neg = (1 - sens) / spec if 0 < spec else np.inf\n",
    "    \n",
    "# print \"True outcomes:\", ytrue\n",
    "# print \"Prediction   :\", ypred\n",
    "print \"Number of cases :\", len(ytrue)\n",
    "print \"Number of deaths:\", np.sum(ytrue)\n",
    "print \"CFR             :\", 100 * (float(np.sum(ytrue)) / len(ytrue))\n",
    "\n",
    "print \"\"\n",
    "print \"Measures of performance\"\n",
    "print \"AUC           :\", auc\n",
    "print \"Brier         :\", brier\n",
    "print \"Calibration   :\", cal\n",
    "print \"Discrimination:\", dis\n",
    "print \"Accuracy      :\", acc\n",
    "print \"Sensitivity   :\", sens\n",
    "print \"Specificity   :\", spec\n",
    "print \"PPV           :\", ppv\n",
    "print \"NPV           :\", npv\n",
    "print \"LR+           :\", lr_pos\n",
    "print \"LR-           :\", lr_neg\n",
    "\n",
    "# print \"Precision (live)  :\", precision[0],\" (specificity for die)\"\n",
    "# print \"Precision (die)   :\", precision[1],\" (specificity for live)\"\n",
    "# print \"Sensitivity (live):\", recall[0]\n",
    "# print \"Sensitivity (die) :\", recall[1]\n",
    "# print \"F1 (live)         :\", f1score[0]\n",
    "# print \"F1 (die)          :\", f1score[1]\n",
    "\n",
    "with open(os.path.join(model_name, 'kgh-comp.txt'), 'w') as of:\n",
    "    of.write(\"Measures of performance\\n\")\n",
    "    of.write(\"AUC           : \" + str(auc) + \"\\n\")\n",
    "    of.write(\"Brier         : \" + str(brier) + \"\\n\")\n",
    "    of.write(\"Calibration   : \" + str(cal) + \"\\n\")\n",
    "    of.write(\"Discrimination: \" + str(dis) + \"\\n\")\n",
    "    of.write(\"Accuracy      : \" + str(acc) + \"\\n\")    \n",
    "    of.write(\"Sensitivity   : \" + str(sens) + \"\\n\")\n",
    "    of.write(\"Specificity   : \" + str(spec) + \"\\n\")\n",
    "    of.write(\"PPV           : \" + str(ppv) + \"\\n\")\n",
    "    of.write(\"NPV           : \" + str(npv) + \"\\n\")\n",
    "    of.write(\"LR+           : \" + str(lr_pos) + \"\\n\")\n",
    "    of.write(\"LR-           : \" + str(lr_neg) + \"\\n\")    \n",
    "    \n",
    "#     of.write(\"Precision (live)  : \" + str(precision[0]) + \" (specificity for die)\\n\")\n",
    "#     of.write(\"Precision (die)   : \" + str(precision[1]) + \" (specificity for live)\\n\")\n",
    "#     of.write(\"Sensitivity (live): \" + str(recall[0]) + \"\\n\")\n",
    "#     of.write(\"Sensitivity (die) : \" + str(recall[1]) + \"\\n\")\n",
    "#     of.write(\"F1 (live)         : \" + str(f1score[0]) + \"\\n\")\n",
    "#     of.write(\"F1 (die)          : \" + str(f1score[1]) + \"\\n\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.plot([0, 1], [0, 1], 'k--', c='grey')\n",
    "plt.plot(fpr, tpr, color='black')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "fig.savefig(os.path.join(model_name, 'kenema-roc-complete.pdf'))\n",
    "\n",
    "cal_table = calibration_table(ytrue, probs, 10)\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot([0.05, 0.95], [0.05, 0.95], '-', c='grey', linewidth=0.5, zorder=1)\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('Predicted Risk')\n",
    "plt.ylabel('Observed Risk')\n",
    "x = cal_table['pred_prob']\n",
    "y = cal_table['true_prob']\n",
    "# f = interp1d(x, y, kind='cubic')\n",
    "# xnew = np.linspace(min(x), max(x), num=50, endpoint=True)    \n",
    "# plt.plot(xnew, f(xnew))\n",
    "plt.plot(x, y, color='black')\n",
    "fig.savefig(os.path.join(model_name, 'kenema-cal-complete.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Resuls on entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to impute, as there is missing data, but can skip and move on to graphs if already run imputation earlier (imputed files are stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i imp_data_folder,test_data_file -o imp_data_files\n",
    "\n",
    "# Imputation in R using MICE\n",
    "library(mice)\n",
    "\n",
    "num_imp <- 50\n",
    "\n",
    "src_data <- read.table(test_data_file, sep=\",\", header=TRUE, na.strings=\"\\\\N\")\n",
    "\n",
    "imp_data <- mice(src_data, meth='pmm', m=num_imp)\n",
    "var_drop <- c(\".imp\", \".id\")\n",
    "imp_data_files <- character(0)\n",
    "for (iter in 1:num_imp) {\n",
    "    comp_data <- complete(imp_data, action=iter)  \n",
    "    comp_data <- comp_data[,!(names(comp_data) %in% var_drop)]\n",
    "    fn <- paste(imp_data_folder, \"/imputation-\", iter, \".csv\", sep=\"\")\n",
    "    write.csv(comp_data, file=fn, row.names=FALSE)\n",
    "    imp_data_files <- c(imp_data_files, fn)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytrue_all = []\n",
    "probs_all = []\n",
    "\n",
    "cfr_list = []\n",
    "auc_list = [] \n",
    "brier_list = [] \n",
    "cal_list = [] \n",
    "dis_list = [] \n",
    "acc_list = []\n",
    "sens_list = [] \n",
    "spec_list = []\n",
    "ppv_list = [] \n",
    "npv_list = []\n",
    "lr_pos_list = []\n",
    "lr_neg_list = []\n",
    "\n",
    "for fn in imp_data_files:\n",
    "    data = pd.read_csv(fn)\n",
    "\n",
    "    x = data[data.columns[1:]].values\n",
    "    ytrue = [int(v) for v in data[data.columns[0]].values]\n",
    "    probs = list(model.predict(x))\n",
    "    \n",
    "    ypred = [int(0.5 < p) for p in probs]\n",
    "    cfr = float(np.sum(ytrue)) / len(ytrue)\n",
    "    \n",
    "    ytrue_all += ytrue\n",
    "    probs_all += probs\n",
    "    \n",
    "    P = N = 0\n",
    "    TP = TN = 0\n",
    "    FP = FN = 0\n",
    "    for i in range(len(ytrue)):\n",
    "        if ytrue[i] == 1:\n",
    "            P += 1\n",
    "            if ypred[i] == 1: TP += 1\n",
    "            else: FN += 1\n",
    "        else:\n",
    "            N += 1\n",
    "            if ypred[i] == 0: TN += 1\n",
    "            else: FP += 1\n",
    "            \n",
    "    sens = float(TP)/P\n",
    "    spec = float(TN)/N\n",
    "\n",
    "    ppv = float(TP) / (TP + FP)\n",
    "    npv = float(TN) / (TN + FN)\n",
    "    \n",
    "    lr_pos = sens / (1 - spec) if spec < 1 else np.inf\n",
    "    lr_neg = (1 - sens) / spec if 0 < spec else np.inf    \n",
    "    \n",
    "    auc = roc_auc_score(ytrue, probs)\n",
    "    brier = brier_score_loss(ytrue, probs)\n",
    "    cal, dis = caldis(ytrue, probs)\n",
    "    acc = accuracy_score(ytrue, ypred)\n",
    "    \n",
    "    cfr_list.append(cfr)\n",
    "    auc_list.append(auc)\n",
    "    brier_list.append(brier)\n",
    "    cal_list.append(cal)\n",
    "    dis_list.append(dis)\n",
    "    acc_list.append(acc)\n",
    "    sens_list.append(sens)\n",
    "    spec_list.append(spec)\n",
    "    ppv_list.append(ppv)\n",
    "    npv_list.append(npv)\n",
    "    lr_pos_list.append(lr_pos)\n",
    "    lr_neg_list.append(lr_neg)    \n",
    "    \n",
    "#     prec0_list.append(precision[0])\n",
    "#     prec1_list.append(precision[1])\n",
    "#     rec0_list.append(recall[0])\n",
    "#     rec1_list.append(recall[1])\n",
    "#     f10_list.append(f1score[0])\n",
    "#     f11_list.append(f1score[1])  \n",
    "\n",
    "cfr_mean = np.mean(cfr_list)\n",
    "auc_mean = np.mean(auc_list)\n",
    "brier_mean = np.mean(brier_list)\n",
    "cal_mean = np.mean(cal_list)\n",
    "dis_mean = np.mean(dis_list)      \n",
    "acc_mean = np.mean(acc_list)\n",
    "sens_mean = np.mean(sens_list)      \n",
    "spec_mean = np.mean(spec_list)\n",
    "ppv_mean = np.mean(ppv_list)\n",
    "npv_mean = np.mean(npv_list)\n",
    "lr_pos_mean = np.mean(lr_pos_list)\n",
    "lr_neg_mean = np.mean(lr_neg_list)\n",
    "\n",
    "# prec0_mean = np.mean(prec0_list)\n",
    "# prec1_mean = np.mean(prec1_list)\n",
    "# rec0_mean = np.mean(rec0_list)\n",
    "# rec1_mean = np.mean(rec1_list)\n",
    "# f10_mean = np.mean(f10_list)\n",
    "# f11_mean = np.mean(f11_list)\n",
    " \n",
    "cfr_dev = np.std(cfr_list)\n",
    "auc_dev = np.std(auc_list)\n",
    "brier_dev = np.std(brier_list)\n",
    "cal_dev = np.std(cal_list)\n",
    "dis_dev = np.std(dis_list)      \n",
    "acc_dev = np.std(acc_list)\n",
    "sens_dev = np.std(sens_list)      \n",
    "spec_dev = np.std(spec_list)\n",
    "ppv_dev = np.std(ppv_list)\n",
    "npv_dev = np.std(npv_list)\n",
    "lr_pos_dev = np.std(lr_pos_list)\n",
    "lr_neg_dev = np.std(lr_neg_list)\n",
    "\n",
    "# prec0_dev = np.std(prec0_list)\n",
    "# prec1_dev = np.std(prec1_list)\n",
    "# rec0_dev = np.std(rec0_list)\n",
    "# rec1_dev = np.std(rec1_list)\n",
    "# f10_dev = np.std(f10_list)\n",
    "# f11_dev = np.std(f11_list)    \n",
    "    \n",
    "print \"Number of cases :\", len(ytrue)\n",
    "print \"Mean CFR        :\", 100 * cfr_mean\n",
    "print \"\"\n",
    "print \"Measures of performance\"\n",
    "print \"AUC           :\", auc_mean, '+/-', auc_dev\n",
    "print \"Brier         :\", brier_mean, '+/-', brier_dev\n",
    "print \"Calibration   :\", cal_mean, '+/-', cal_dev\n",
    "print \"Discrimination:\", dis_mean, '+/-', dis_dev\n",
    "print \"Accuracy      :\", acc_mean, '+/-', acc_dev\n",
    "print \"Sensitivity   :\", sens_mean, '+/-', sens_dev\n",
    "print \"Specificity   :\", spec_mean, '+/-', spec_dev\n",
    "print \"PPV           :\", ppv_mean, '+/-', ppv_dev\n",
    "print \"NPV           :\", npv_mean, '+/-', npv_dev\n",
    "print \"LR+           :\", lr_pos_mean, '+/-', lr_pos_dev\n",
    "print \"LR-           :\", lr_neg_mean, '+/-', lr_neg_dev\n",
    "\n",
    "\n",
    "# print \"Precision (live)  :\", prec0_mean, '+/-', prec0_dev,\" (specificity for die)\"\n",
    "# print \"Precision (die)   :\", prec1_mean, '+/-', prec1_dev,\" (specificity for live)\"\n",
    "# print \"Sensitivity (live):\", rec0_mean, '+/-', rec0_dev\n",
    "# print \"Sensitivity (die) :\", rec1_mean, '+/-', rec1_dev\n",
    "# print \"F1 (live)         :\", f10_mean, '+/-', f10_dev\n",
    "# print \"F1 (die)          :\", f11_mean, '+/-', f11_dev\n",
    "\n",
    "with open(os.path.join(model_name, 'kgh-imp.txt'), 'w') as of:\n",
    "    of.write(\"Measures of performance\\n\")\n",
    "    of.write(\"AUC           : \" + str(auc_mean) + \"+/-\" + str(auc_dev) + \"\\n\")\n",
    "    of.write(\"Brier         : \" + str(brier_mean) + \"+/-\" + str(brier_dev) + \"\\n\")\n",
    "    of.write(\"Calibration   : \" + str(cal_mean) + \"+/-\" + str(cal_dev) + \"\\n\")\n",
    "    of.write(\"Discrimination: \" + str(dis_mean) + \"+/-\" + str(dis_dev) + \"\\n\")\n",
    "    of.write(\"Accuracy      : \" + str(acc_mean) + \"+/-\" + str(acc_dev) + \"\\n\")\n",
    "    of.write(\"Sensitivity   : \" + str(sens_mean) + \"+/-\" + str(sens_dev) + \"\\n\")\n",
    "    of.write(\"Specificity   : \" + str(spec_mean) + \"+/-\" + str(spec_dev) + \"\\n\")    \n",
    "    of.write(\"PPV           : \" + str(ppv_mean) + \"+/-\" + str(ppv_dev) + \"\\n\")\n",
    "    of.write(\"NPV           : \" + str(npv_mean) + \"+/-\" + str(npv_dev) + \"\\n\")     \n",
    "    of.write(\"LR+           : \" + str(lr_pos_mean) + \"+/-\" + str(lr_pos_dev) + \"\\n\")\n",
    "    of.write(\"LR-           : \" + str(lr_neg_mean) + \"+/-\" + str(lr_neg_dev) + \"\\n\") \n",
    "\n",
    "#     of.write(\"Precision (live)  : \" + str(prec0_mean) + \"+/-\" + str(prec0_dev) + \" (specificity for die)\\n\")\n",
    "#     of.write(\"Precision (die)   : \" + str(prec1_mean) + \"+/-\" + str(prec1_dev) + \" (specificity for live)\\n\")\n",
    "#     of.write(\"Sensitivity (live): \" + str(rec0_mean) + \"+/-\" + str(rec0_dev) + \"\\n\")\n",
    "#     of.write(\"Sensitivity (die) : \" + str(rec1_mean) + \"+/-\" + str(rec1_dev) + \"\\n\")\n",
    "#     of.write(\"F1 (live)         : \" + str(f10_mean) + \"+/-\" + str(f10_dev) + \"\\n\")\n",
    "#     of.write(\"F1 (die)          : \" + str(f11_mean) + \"+/-\" + str(f11_dev) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-0.2, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.plot([0, 1], [0, 1], 'k--', c='grey', linewidth=0.5)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "imp_fpr = []\n",
    "imp_tpr = []\n",
    "\n",
    "for fn in imp_data_files:\n",
    "    data = pd.read_csv(fn)\n",
    "    \n",
    "    x = data[data.columns[1:]].values\n",
    "    ytrue = [int(v) for v in data[data.columns[0]].values]\n",
    "    probs = list(model.predict(x))\n",
    "    \n",
    "    # Drawing the ROC from each imputed dataset\n",
    "    fpr, tpr, thresholds = roc_curve(ytrue, probs) \n",
    "    plt.plot(fpr, tpr, color='black', alpha=0.05)\n",
    "    imp_fpr += [fpr]\n",
    "    imp_tpr += [tpr]\n",
    "    \n",
    "# Macro-average of ROC cuve over all imputations.\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate(imp_fpr))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(0, len(imp_fpr)):\n",
    "    mean_tpr += interp(all_fpr, imp_fpr[i], imp_tpr[i])\n",
    "mean_tpr /= len(imp_fpr)\n",
    "\n",
    "plt.plot(all_fpr, mean_tpr, color='red', alpha=1.0)\n",
    "fig.savefig(os.path.join(model_name, 'kenema-roc-imputed.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calibration curve\n",
    "\n",
    "smooth = False\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot([0.05, 0.95], [0.05, 0.95], '-', c='grey', linewidth=0.5, zorder=1)\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('Predicted Risk')\n",
    "plt.ylabel('Observed Risk')\n",
    "\n",
    "imp_ppr = []\n",
    "imp_tpr = []\n",
    "\n",
    "for fn in imp_data_files:\n",
    "    data = pd.read_csv(fn)\n",
    "    \n",
    "    x = data[data.columns[1:]].values\n",
    "    ytrue = [int(v) for v in data[data.columns[0]].values]\n",
    "    probs = list(model.predict(x))\n",
    "    \n",
    "    # Drawing the calibration from each imputed dataset\n",
    "    cal_table = calibration_table(ytrue, probs, 10)\n",
    "\n",
    "    x = cal_table['pred_prob']\n",
    "    y = cal_table['true_prob']\n",
    "    if smooth:\n",
    "        f = interp1d(x, y, kind='cubic')\n",
    "        xnew = np.linspace(min(x), max(x), num=50, endpoint=True)    \n",
    "        plt.plot(xnew, f(xnew), color='black', alpha=0.1)    \n",
    "    else:    \n",
    "        plt.plot(x, y, color='black', alpha=0.1)\n",
    "    imp_ppr += [x]\n",
    "    imp_tpr += [y]\n",
    "    \n",
    "all_ppr = np.unique(np.concatenate(imp_ppr))\n",
    "\n",
    "mean_tpr = np.zeros_like(all_ppr)\n",
    "for i in range(0, len(imp_ppr)):\n",
    "    mean_tpr += interp(all_ppr, imp_ppr[i], imp_tpr[i])\n",
    "mean_tpr /= len(imp_ppr)\n",
    "\n",
    "if smooth:\n",
    "    xnew = np.linspace(min(all_ppr), max(all_ppr), num=2 * len(all_ppr), endpoint=True)    \n",
    "    f = interp1d(all_ppr, mean_tpr, kind='cubic')    \n",
    "    plt.plot(xnew, f(xnew), color='red', alpha=1.0)\n",
    "else:\n",
    "    plt.plot(all_ppr, mean_tpr, color='red', alpha=1.0)\n",
    "\n",
    "fig.savefig(os.path.join(model_name, 'kenema-cal-imputed.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
