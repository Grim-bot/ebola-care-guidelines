{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook evaluates different models and gives the minimum and maximum contribution from each term (needed for the Ebola CARE app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy import interp\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogRegModel(object):\n",
    "    def __init__(self, fn, model_format='MICE'):\n",
    "        self.intercept = 0\n",
    "        self.names = []        \n",
    "        self.terms = []\n",
    "        if model_format == 'MICE':\n",
    "            self.loadTermsMICE(fn)\n",
    "        elif model_format == 'GLM':\n",
    "            self.loadTermsGLM(fn)\n",
    "            \n",
    "    def setIntercept(self, b0):\n",
    "        self.intercept = b0\n",
    "\n",
    "    def addTerm(self, t):\n",
    "        self.terms += [t]\n",
    "        self.names += [t.name]        \n",
    "\n",
    "    def linfeat(self, x):\n",
    "        zmat = []\n",
    "        for i in range(0, len(x)):\n",
    "            xrow = x[i]\n",
    "            zrow = [1.0]\n",
    "            for j in range(0, len(self.terms)):\n",
    "                t = self.terms[j]\n",
    "                zrow += t.linearFeatures(xrow[j])\n",
    "            zmat += [zrow]\n",
    "        return zmat\n",
    "\n",
    "    def lincoeff(self):\n",
    "        coeff = [self.intercept]\n",
    "        for t in self.terms:\n",
    "            coeff += t.coeffs\n",
    "        return coeff    \n",
    "                \n",
    "    def sigmoid(self, v):\n",
    "        return 1.0 / (1.0 + np.exp(-v))\n",
    "            \n",
    "    def predict(self, x):\n",
    "        z = self.linfeat(x)\n",
    "        theta = self.lincoeff()\n",
    "        prob = []\n",
    "        n = len(z)\n",
    "        for i in range(0, n):            \n",
    "            p = self.sigmoid(np.dot(z[i], theta))\n",
    "            prob += [p]\n",
    "        return np.array(prob)\n",
    "\n",
    "    def loatVarTypes(self, data_fn, dict_fn):\n",
    "        var = []\n",
    "        vtyp= []\n",
    "        with open(data_fn) as f:\n",
    "            var = f.readlines()[0].split(',')\n",
    "        with open(dict_fn) as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                if not line: continue\n",
    "                _, t = line.split(',')[0:2]\n",
    "                vtyp += [t]\n",
    "        for t in self.terms:\n",
    "            pos = var.index(t.name)\n",
    "            t.vtyp = vtyp[pos]\n",
    "            \n",
    "    def saveOddRatios(self, x, fn):\n",
    "        theta = self.lincoeff()\n",
    "        scale = [1.0] * len(theta)\n",
    "\n",
    "        t = 0\n",
    "        ts = 1\n",
    "        for term in self.terms:\n",
    "            vrang = term.varRanges(x[:,t]) \n",
    "            for i in range(0, len(vrang)):\n",
    "                scale[ts] = vrang[i]\n",
    "                if scale[ts] < 1: scale[ts] = 1.0 / scale[ts]\n",
    "                ts = ts + 1                \n",
    "            t = t + 1\n",
    "\n",
    "        theta *= np.array(scale)\n",
    "        odds = np.exp(theta)\n",
    "        ts = 1\n",
    "        with open(fn, 'w') as f:                \n",
    "            for term in self.terms:\n",
    "                vnam = term.varNames()\n",
    "                for i in range(0, len(vnam)):\n",
    "                    f.write(vnam[i] + ' ' + str(odds[ts]) + '\\n')\n",
    "                    ts = ts + 1\n",
    "                    \n",
    "    def getFormula(self, digits):\n",
    "        formula = str(round(self.intercept, digits))\n",
    "        for term in self.terms:\n",
    "            formula = formula + term.getFormula(digits)\n",
    "        return formula\n",
    "        \n",
    "    def saveRanges(self, x, fn):\n",
    "        nrows = len(x)\n",
    "        nvars = len(self.terms)\n",
    "        values = np.zeros((nrows, nvars))\n",
    "        for i in range(0, nrows):\n",
    "            xrow = x[i]\n",
    "            vrow = values[i]\n",
    "            for t in range(0, len(self.terms)):\n",
    "                term = self.terms[t]\n",
    "                vrow[t] = term.value(xrow[t])\n",
    "\n",
    "        with open(fn, 'w') as f:                \n",
    "            for t in range(0, len(self.terms)):\n",
    "                term = self.terms[t]\n",
    "                mint = min(values[:,t])\n",
    "                maxt = max(values[:,t])\n",
    "                f.write(term.name + ' ' + str(mint) + ' ' + str(maxt) + '\\n')            \n",
    "\n",
    "    def saveRCSTerms(self, x, d):\n",
    "        for t in range(0, len(self.terms)):            \n",
    "            term = self.terms[t]\n",
    "            if not term.isRCS: continue\n",
    "            yvalues = []\n",
    "            xmin = x[:,t].min()\n",
    "            xmax = x[:,t].max()                \n",
    "            xvalues = np.linspace(xmin, xmax, 100)\n",
    "            for xt in xvalues:\n",
    "                y = term.value(xt)\n",
    "                yvalues += [y]\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.plot(xvalues, yvalues)\n",
    "            plt.xlabel(term.name, labelpad=20)\n",
    "            plt.title('RCS term for ' + term.name)\n",
    "            fig.savefig(os.path.join(d, 'rcs_' + term.name + '.pdf'))\n",
    "                \n",
    "    def loadTermsMICE(self, fn):\n",
    "        rcsCoeffs = None;\n",
    "        lines = []\n",
    "        with open(fn) as ifn:    \n",
    "            lines = ifn.readlines()\n",
    "\n",
    "        pos = lines[0].index('est') + 2\n",
    "\n",
    "        n = 1;\n",
    "        while n < len(lines):\n",
    "            line = lines[n]     \n",
    "            n += 1\n",
    "            \n",
    "            s = line[0:pos].strip()\n",
    "            \n",
    "            v = s.split()\n",
    "            if line[0] == ' ' or len(v) == 1: break\n",
    "            valueStr = v[-1]\n",
    "            value = float(valueStr)\n",
    "\n",
    "            pos0 = s.index(valueStr)\n",
    "            var = s[0:pos0].strip()\n",
    "\n",
    "            if 'rcs' in var and var.index('rcs') == 0:\n",
    "                pos1 = var.rfind(')')\n",
    "                rcsString = var[4:pos1]\n",
    "                pieces = rcsString.split('c')\n",
    "                part1 = pieces[0].split(',')\n",
    "                varName = part1[0].strip()\n",
    "                rcsOrder = int(part1[1].strip())\n",
    "                knotStr = pieces[1].replace(\"(\", \"\").replace(\")\", \"\").split(\",\")\n",
    "                rcsKnots = [float(k) for k in knotStr]\n",
    "                coeffOrder = len(var) - len(var.replace(\"'\", \"\"))\n",
    "                \n",
    "                if coeffOrder == 0:\n",
    "                    rcsCoeffs = [0.0] * (rcsOrder - 1);\n",
    "                if rcsCoeffs: \n",
    "                    rcsCoeffs[coeffOrder] = value;\n",
    "\n",
    "                if coeffOrder == rcsOrder - 2:\n",
    "                    term = RCSTerm(varName, rcsOrder, rcsCoeffs, rcsKnots)\n",
    "                    self.addTerm(term)              \n",
    "            else:\n",
    "                if var == '(Intercept)':\n",
    "                    self.setIntercept(value);\n",
    "                else:\n",
    "                    term = LinearTerm(var, value)\n",
    "                    self.addTerm(term)\n",
    "\n",
    "    def loadTermsGLM(self, fn):               \n",
    "        rcsCoeffs = None;\n",
    "        lines = []\n",
    "        with open(fn) as ifn:    \n",
    "            lines = ifn.readlines()\n",
    "\n",
    "        reading = False\n",
    "        n = 1;\n",
    "        while n < len(lines):\n",
    "            line = lines[n]\n",
    "            n += 1\n",
    "\n",
    "            if '(Intercept)' in line: \n",
    "                reading = True\n",
    "                val = line.split()[1]\n",
    "                pos = line.index(val) + len(val)\n",
    "                \n",
    "                # This breaks easily if file is not properly formatted:\n",
    "                #pos = line.index('Estimate') + 8\n",
    "                #continue\n",
    "            \n",
    "            if not reading: continue\n",
    "            \n",
    "            s = line[0:pos].strip()\n",
    "            \n",
    "            v = s.split()\n",
    "            if line[0] == ' ' or len(v) == 1 or v[0] == '---': break   \n",
    "            valueStr = v[-1]\n",
    "            value = float(valueStr)\n",
    "\n",
    "            pos0 = s.index(valueStr)\n",
    "            var = s[0:pos0].strip()\n",
    "\n",
    "            if 'rcs' in var and var.index('rcs') == 0:\n",
    "                pos1 = var.rfind(')')\n",
    "                rcsString = var[4:pos1]\n",
    "                pieces = rcsString.split('c')\n",
    "                part1 = pieces[0].split(',')\n",
    "                varName = part1[0].strip()\n",
    "                rcsOrder = int(part1[1].strip())\n",
    "                knotStr = pieces[1].replace(\"(\", \"\").replace(\")\", \"\").split(\",\")\n",
    "                rcsKnots = [float(k) for k in knotStr]\n",
    "                coeffOrder = len(var) - len(var.replace(\"'\", \"\"))\n",
    "                \n",
    "                if coeffOrder == 0:\n",
    "                    rcsCoeffs = [0.0] * (rcsOrder - 1);\n",
    "                if rcsCoeffs: \n",
    "                    rcsCoeffs[coeffOrder] = value;\n",
    "\n",
    "                if coeffOrder == rcsOrder - 2:\n",
    "                    term = RCSTerm(varName, rcsOrder, rcsCoeffs, rcsKnots)\n",
    "                    self.addTerm(term)              \n",
    "            else:\n",
    "                if var == '(Intercept)':\n",
    "                    self.setIntercept(value);\n",
    "                else:\n",
    "                    term = LinearTerm(var, value)\n",
    "                    self.addTerm(term)\n",
    "                    \n",
    "class ModelTerm(object):\n",
    "    def __init__(self, name):\n",
    "        self.isRCS = False\n",
    "        self.name = name\n",
    "        self.vtyp = 'float'\n",
    "        self.coeffs = []\n",
    "    def linearFeatures(self, x):\n",
    "        return [0.0] * len(self.coeffs)\n",
    "    def varRanges(self, x):\n",
    "        # Scale coefficients by IQR (in floating-point variables) or\n",
    "        # closest power-of-ten for integer variables.        \n",
    "        if self.vtyp == 'category': \n",
    "            return [1]\n",
    "        elif self.vtyp == 'int':\n",
    "            n = np.floor(np.log10(max(x)))\n",
    "            return [np.power(10, n)]\n",
    "        elif self.vtyp == 'float':                                \n",
    "            return [np.percentile(x, 75) - np.percentile(x, 25)]\n",
    "    def getFormula(self, digits):\n",
    "        return ''\n",
    "    def varNames(self):\n",
    "        return [self.name]\n",
    "    def value(self, x): \n",
    "        return np.dot(self.coeffs, self.linearFeatures(x))\n",
    "    \n",
    "class LinearTerm(ModelTerm):\n",
    "    def __init__(self, name, c):\n",
    "        ModelTerm.__init__(self, name)\n",
    "        self.coeffs = [c]\n",
    "\n",
    "    def linearFeatures(self, x):\n",
    "        return [x]\n",
    "\n",
    "    def getFormula(self, digits):\n",
    "        c = self.coeffs[0]\n",
    "        sign = ' + ' if 0 < c else ' - '\n",
    "        return sign + str(round(abs(c), digits)) + ' ' + self.name\n",
    "    \n",
    "    def __str__(self):\n",
    "        res = \"Linear term for \" + self.name + \"\\n\"\n",
    "        res += \"  Coefficient: \" + str(self.coeffs[0])\n",
    "        return res\n",
    "\n",
    "class RCSTerm(ModelTerm):\n",
    "    def __init__(self, name, k, c, kn):\n",
    "        ModelTerm.__init__(self, name)\n",
    "        self.isRCS = True        \n",
    "        self.order = k\n",
    "        self.coeffs = list(c)\n",
    "        self.knots = list(kn)\n",
    "\n",
    "    def cubic(self, u):\n",
    "        t = np.maximum(0, u)\n",
    "        return t * t * t\n",
    "    \n",
    "    def rcs(self, x, term):\n",
    "        k = len(self.knots) - 1\n",
    "        j = term - 1\n",
    "        t = self.knots\n",
    "        c = (t[k] - t[0]) * (t[k] - t[0])\n",
    "        value = +self.cubic(x - t[j]) \\\n",
    "                -self.cubic(x - t[k - 1]) * (t[k] - t[j])/(t[k] - t[k-1]) \\\n",
    "                +self.cubic(x - t[k]) * (t[k - 1] - t[j])/(t[k] - t[k-1]) \n",
    "        return value / c\n",
    "    \n",
    "    def rcsform(self, term, digits):\n",
    "        k = len(self.knots) - 1\n",
    "        j = term - 1\n",
    "        t = self.knots\n",
    "        c = (t[k] - t[0]) * (t[k] - t[0])\n",
    "          \n",
    "        c0 = self.coeffs[term] / c\n",
    "        sign0 = ' + ' if 0 < c0 else ' - '\n",
    "        s = sign0 + str(round(abs(c0), digits[0])) + ' max(%s - ' + str(round(t[j], 3)) + ', 0)^3' \n",
    "    \n",
    "        c1 = self.coeffs[term] * (t[k] - t[j])/(c * (t[k] - t[k-1]))    \n",
    "        sign1 = ' - ' if 0 < c1 else ' + '\n",
    "        s += sign1 + str(round(abs(c1), digits[1])) + ' max(%s - ' + str(round(t[k - 1], 3)) + ', 0)^3' \n",
    "    \n",
    "        c2 = self.coeffs[term] * (t[k - 1] - t[j])/(c * (t[k] - t[k-1]))\n",
    "        sign2 = ' + ' if 0 < c2 else ' - '        \n",
    "        s += sign2 + str(round(c2, digits[2])) + ' max(%s - ' + str(round(t[k], 3)) + ', 0)^3' \n",
    "    \n",
    "        return s\n",
    "\n",
    "    def linearFeatures(self, x):\n",
    "        feat = [0.0] * (self.order - 1)\n",
    "        feat[0] = x\n",
    "        for t in range(1, self.order - 1):\n",
    "            feat[t] = self.rcs(x, t)\n",
    "        return feat           \n",
    "\n",
    "    def varRanges(self, x):\n",
    "        rang = [0.0] * (self.order - 1)\n",
    "        rang[0] = np.percentile(x, 75) - np.percentile(x, 25)\n",
    "        for i in range(1, self.order - 1):\n",
    "            y = self.rcs(x, i)\n",
    "            rang[i] = np.percentile(y, 75) - np.percentile(y, 25)            \n",
    "        return rang\n",
    "    \n",
    "    def varNames(self):\n",
    "        nam = [''] * (self.order - 1)\n",
    "        nam[0] = self.name\n",
    "        for i in range(1, self.order - 1):\n",
    "            nam[i] = self.name + (\"'\" * i)\n",
    "        return nam\n",
    "    \n",
    "    def getFormula(self, digits):        \n",
    "        c = self.coeffs[0]\n",
    "        sign = ' + ' if 0 < c else ' - '\n",
    "        s = sign + str(round(abs(c), digits)) + ' ' + self.name\n",
    "        for i in range(1, self.order - 1):\n",
    "            s = s + self.rcsform(i, [digits] * 3) % (self.name, self.name, self.name)\n",
    "        return s\n",
    "    \n",
    "    def __str__(self):\n",
    "        res = \"RCS term of order \" + str(self.order) + \" for \" + self.name + \"\\n\"\n",
    "        res += \"  Coefficients:\";\n",
    "        for i in range(0, len(self.coeffs)):\n",
    "            res += \" \" + str(self.coeffs[i])\n",
    "        res += \"\\n\"\n",
    "        res += \"  Knots:\"\n",
    "        for i in range(0, len(self.knots)):\n",
    "            res += \" \" + str(self.knots[i])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Measurements inspired by Philip Tetlock's \"Expert Political Judgment\"\n",
    "Equations take from Yaniv, Yates, & Smith (1991):\n",
    "  \"Measures of Descrimination Skill in Probabilistic Judgement\"\n",
    "\"\"\"\n",
    "\n",
    "def calibration(outcome, prob, n_bins=10):\n",
    "    \"\"\"Calibration measurement for a set of predictions.\n",
    "    When predicting events at a given probability, how far is frequency\n",
    "    of positive outcomes from that probability?\n",
    "    NOTE: Lower scores are better\n",
    "    prob: array_like, float\n",
    "        Probability estimates for a set of events\n",
    "    outcome: array_like, bool\n",
    "        If event predicted occurred\n",
    "    n_bins: int\n",
    "        Number of judgement categories to prefrom calculation over.\n",
    "        Prediction are binned based on probability, since \"discrete\" \n",
    "        probabilities aren't required. \n",
    "    \"\"\"\n",
    "    prob = np.array(prob)\n",
    "    outcome = np.array(outcome)\n",
    "\n",
    "    c = 0.0\n",
    "    # Construct bins\n",
    "    judgement_bins = np.arange(n_bins + 1.0) / n_bins\n",
    "    # Which bin is each prediction in?\n",
    "    bin_num = np.digitize(prob,judgement_bins)\n",
    "    for j_bin in np.unique(bin_num):\n",
    "        # Is event in bin\n",
    "        in_bin = bin_num == j_bin\n",
    "        # Predicted probability taken as average of preds in bin\n",
    "        predicted_prob = np.mean(prob[in_bin])\n",
    "        # How often did events in this bin actually happen?\n",
    "        true_bin_prob = np.mean(outcome[in_bin])\n",
    "        # Squared distance between predicted and true times num of obs\n",
    "        c += np.sum(in_bin) * ((predicted_prob - true_bin_prob) ** 2)\n",
    "    return c / len(prob)\n",
    "\n",
    "\n",
    "def calibration_table(outcome, prob, n_bins=10):\n",
    "    \"\"\"Calibration measurement for a set of predictions.\n",
    "    When predicting events at a given probability, how far is frequency\n",
    "    of positive outcomes from that probability?\n",
    "    NOTE: Lower scores are better\n",
    "    prob: array_like, float\n",
    "        Probability estimates for a set of events\n",
    "    outcome: array_like, bool\n",
    "        If event predicted occurred\n",
    "    n_bins: int\n",
    "        Number of judgement categories to prefrom calculation over.\n",
    "        Prediction are binned based on probability, since \"discrete\" \n",
    "        probabilities aren't required. \n",
    "    \"\"\"\n",
    "    prob = np.array(prob)\n",
    "    outcome = np.array(outcome)\n",
    "\n",
    "    c = 0.0\n",
    "    # Construct bins\n",
    "    judgement_bins = np.arange(n_bins + 1.0) / n_bins\n",
    "    # Which bin is each prediction in?\n",
    "    bin_num = np.digitize(prob, judgement_bins)\n",
    "\n",
    "    counts = []\n",
    "    true_prob = []\n",
    "    pred_prob = []\n",
    "    for j_bin in np.arange(n_bins + 1):\n",
    "        # Is event in bin\n",
    "        in_bin = bin_num == j_bin\n",
    "#         # Predicted probability taken as average of preds in bin        \n",
    "        predicted_prob = np.mean(prob[in_bin])\n",
    "#         # How often did events in this bin actually happen?\n",
    "        true_bin_prob = np.mean(outcome[in_bin])\n",
    "        counts.append(np.sum(0 <= prob[in_bin]))\n",
    "        true_prob.append(true_bin_prob) \n",
    "        pred_prob.append(predicted_prob)\n",
    "    \n",
    "    cal_table = pd.DataFrame({'pred_prob':pd.Series(np.array(pred_prob)), \n",
    "                              'count':pd.Series(np.array(counts)),\n",
    "                              'true_prob':pd.Series(np.array(true_prob))}, \n",
    "                              columns=['pred_prob', 'count', 'true_prob'])\n",
    "    cal_table.dropna(inplace=True)\n",
    "    return cal_table \n",
    "\n",
    "\n",
    "def discrimination(outcome, prob, n_bins=10):\n",
    "    \"\"\"Discrimination measurement for a set of predictions.\n",
    "    For each judgement category, how far from the base probability\n",
    "    is the true frequency of that bin?\n",
    "    NOTE: High scores are better\n",
    "    prob: array_like, float\n",
    "        Probability estimates for a set of events\n",
    "    outcome: array_like, bool\n",
    "        If event predicted occurred\n",
    "    n_bins: int\n",
    "        Number of judgement categories to prefrom calculation over.\n",
    "        Prediction are binned based on probability, since \"discrete\" \n",
    "        probabilities aren't required. \n",
    "    \"\"\"\n",
    "    prob = np.array(prob)\n",
    "    outcome = np.array(outcome)\n",
    "\n",
    "    d = 0.0\n",
    "    # Base frequency of outcomes\n",
    "    base_prob = np.mean(outcome)\n",
    "    # Construct bins\n",
    "    judgement_bins = np.arange(n_bins + 1.0) / n_bins\n",
    "    # Which bin is each prediction in?\n",
    "    bin_num = np.digitize(prob,judgement_bins)\n",
    "    for j_bin in np.unique(bin_num):\n",
    "        in_bin = bin_num == j_bin\n",
    "        true_bin_prob = np.mean(outcome[in_bin])\n",
    "        # Squared distance between true and base times num of obs\n",
    "        d += np.sum(in_bin) * ((true_bin_prob - base_prob) ** 2)\n",
    "    return d / len(prob)\n",
    "\n",
    "def caldis(outcome, probs, n_bins=10):\n",
    "    c = calibration(outcome, probs, n_bins)\n",
    "    d = discrimination(outcome, probs, n_bins)\n",
    "    return c, d  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel_model = 1\n",
    "\n",
    "if sel_model == 1:\n",
    "    model_name = 'min'\n",
    "if sel_model == 2:\n",
    "    model_name = 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load data, model, generate test dataset, save minmax ranges for coefficients and odd-ratios\n",
    "imc_data_folder = '../data'\n",
    "imc_data_file = os.path.join(imc_data_folder, 'data.csv')\n",
    "imc_dict_file = os.path.join(imc_data_folder, 'dictionary.csv')\n",
    "imc_data = pd.read_csv(imc_data_file, na_values=\"\\\\N\")\n",
    "\n",
    "model_params = os.path.join(model_name, 'mice.txt')\n",
    "model_ranges= os.path.join(model_name, 'minmax.txt')\n",
    "model_oddratios = os.path.join(model_name, 'oddratios.txt')\n",
    "\n",
    "model = LogRegModel(model_params)\n",
    "\n",
    "variables = ['Disposition'] + model.names\n",
    "test_data = imc_data[variables].dropna()\n",
    "x = test_data[test_data.columns[1:]].values\n",
    "\n",
    "model.saveRanges(x, model_ranges)\n",
    "model.loatVarTypes(imc_data_file, imc_dict_file)\n",
    "model.saveOddRatios(x, model_oddratios)\n",
    "model.saveRCSTerms(x, model_name)\n",
    "print model.getFormula(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Performance measures\n",
    "\n",
    "ytrue = [int(v) for v in test_data[test_data.columns[0]].values]\n",
    "probs = model.predict(x)\n",
    "ypred = [int(0.4 < p) for p in probs]\n",
    "\n",
    "auc = roc_auc_score(ytrue, probs)\n",
    "fpr, tpr, thresholds = roc_curve(ytrue, probs) \n",
    "brier = brier_score_loss(ytrue, probs)\n",
    "cal, dis = caldis(ytrue, probs)\n",
    "acc = accuracy_score(ytrue, ypred)\n",
    "precision, recall, f1score, support = precision_recall_fscore_support(ytrue, ypred)\n",
    "\n",
    "P = N = 0\n",
    "TP = TN = 0\n",
    "for i in range(len(ytrue)):\n",
    "#     print i, probs[i], ypred[i], ytrue[i]\n",
    "    if ytrue[i] == 1:\n",
    "        P += 1\n",
    "        if ypred[i] == 1: TP += 1\n",
    "    else:\n",
    "        N += 1\n",
    "        if ypred[i] == 0: TN += 1\n",
    "            \n",
    "sens = float(TP)/P            \n",
    "spec = float(TN)/N\n",
    "        \n",
    "# print \"True outcomes:\", ytrue\n",
    "# print \"Prediction   :\", ypred\n",
    "print \"Number of cases :\", len(ytrue)\n",
    "print \"Number of deaths:\", np.sum(ytrue)\n",
    "print \"CFR             :\", 100 * (float(np.sum(ytrue)) / len(ytrue))\n",
    "\n",
    "print \"\"\n",
    "print \"Measures of performance\"\n",
    "print \"AUC           :\", auc\n",
    "print \"Brier         :\", brier\n",
    "print \"Calibration   :\", cal\n",
    "print \"Discrimination:\", dis\n",
    "print \"Accuracy      :\", acc\n",
    "print \"Sensitivity   :\", sens\n",
    "print \"Specificity   :\", spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Averaged ROC curve\n",
    "\n",
    "boot_folder = os.path.join(model_name, 'boot')\n",
    "imp_folder = os.path.join(model_name, 'imp')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim([-0.2, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.plot([0, 1], [0, 1], 'k--', c='grey', linewidth=0.5)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "data_files = glob.glob(imp_folder + '/imputation-*.csv')\n",
    "imp_fpr = []\n",
    "imp_tpr = []\n",
    "for fn in data_files:    \n",
    "    dat = pd.read_csv(fn, na_values=\"\\\\N\")[variables]\n",
    "    val = dat[dat.columns[1:]].values\n",
    "    \n",
    "    pos0 = fn.index(\"imputation-\") + 11\n",
    "    pos1 = fn.index(\".csv\")\n",
    "    idx = fn[pos0:pos1]\n",
    "    \n",
    "    index_files = glob.glob(boot_folder + '/index-' + idx + '*.txt')\n",
    "    model_files = glob.glob(boot_folder + '/model-' + idx + '*.txt')\n",
    "    \n",
    "    # Micro-averaging the ROC curves from bootstrap samples:\n",
    "    # http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    ytrue = []\n",
    "    probs = []\n",
    "    ypred = []\n",
    "    nboot = len(index_files)\n",
    "    for b in range(0, nboot):        \n",
    "        rows = []\n",
    "        with open(index_files[b]) as ifile:\n",
    "            lines = ifile.readlines()\n",
    "            for line in lines:\n",
    "                pieces = line.split()[1:]\n",
    "                rows += [int(i) - 1 for i in pieces]\n",
    "\n",
    "        ytrue += [int(v) for v in dat[dat.columns[0]].values[rows]]\n",
    "        x = val[rows,:]\n",
    "        model = LogRegModel(model_files[b], model_format='GLM')\n",
    "        pboot = model.predict(x)\n",
    "        probs += list(pboot)\n",
    "        ypred += [int(0.5 < p) for p in pboot]\n",
    "\n",
    "    auc = roc_auc_score(ytrue, probs)\n",
    "    fpr, tpr, thresholds = roc_curve(ytrue, probs) \n",
    "    plt.plot(fpr, tpr, color='black', alpha=0.05)\n",
    "    imp_fpr += [fpr]\n",
    "    imp_tpr += [tpr]    \n",
    "\n",
    "# Macro-average of ROC cuve over all imputations.\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate(imp_fpr))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(0, len(imp_fpr)):\n",
    "    mean_tpr += interp(all_fpr, imp_fpr[i], imp_tpr[i])\n",
    "mean_tpr /= len(imp_fpr)\n",
    "\n",
    "plt.plot(all_fpr, mean_tpr, color='red', alpha=1.0)\n",
    "\n",
    "fig.savefig(os.path.join(model_name, 'average-roc-bootstrap.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Average calibration plot\n",
    "\n",
    "boot_folder = os.path.join(model_name, 'boot')\n",
    "imp_folder = os.path.join(model_name, 'imp')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# plt.plot([0, 1], [0, 1], '-', c='grey', linewidth=0.8 * 1, zorder=1)\n",
    "plt.plot([0.05, 0.95], [0.05, 0.95], '-', c='grey', linewidth=0.5, zorder=1)\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('Predicted Risk')\n",
    "plt.ylabel('Observed Risk')\n",
    "# lgnd = plt.legend(loc='lower right', scatterpoints=1, fontsize=10) \n",
    "\n",
    "data_files = glob.glob(imp_folder + '/imputation-*.csv')\n",
    "imp_ppr = []\n",
    "imp_tpr = []\n",
    "for fn in data_files:    \n",
    "    dat = pd.read_csv(fn, na_values=\"\\\\N\")[variables]\n",
    "    val = dat[dat.columns[1:]].values\n",
    "    \n",
    "    pos0 = fn.index(\"imputation-\") + 11\n",
    "    pos1 = fn.index(\".csv\")\n",
    "    idx = fn[pos0:pos1]\n",
    "    \n",
    "    index_files = glob.glob(boot_folder + '/index-' + idx + '*.txt')\n",
    "    model_files = glob.glob(boot_folder + '/model-' + idx + '*.txt')\n",
    "    \n",
    "    ytrue = []\n",
    "    probs = []\n",
    "    ypred = []    \n",
    "    nboot = len(index_files)\n",
    "    for b in range(0, nboot):        \n",
    "        rows = []\n",
    "        with open(index_files[b]) as ifile:\n",
    "            lines = ifile.readlines()\n",
    "            for line in lines:\n",
    "                pieces = line.split()[1:]\n",
    "                rows += [int(i) - 1 for i in pieces]\n",
    "\n",
    "        ytrue += [int(v) for v in dat[dat.columns[0]].values[rows]]\n",
    "        x = val[rows,:]\n",
    "        model = LogRegModel(model_files[b], model_format='GLM')\n",
    "        pboot = model.predict(x)\n",
    "        probs += list(pboot)\n",
    "        ypred += [int(0.5 < p) for p in pboot]\n",
    "    \n",
    "    cal_table = calibration_table(ytrue, probs, 10)\n",
    "#     sizes = cal_table['count'] / 20\n",
    "#     plt.scatter(cal_table['pred_prob'], cal_table['true_prob'], s=sizes, c='red', marker='o', lw = 0, alpha=0.8, zorder=2)\n",
    "\n",
    "    x = cal_table['pred_prob']\n",
    "    y = cal_table['true_prob']\n",
    "    f = interp1d(x, y, kind='cubic')\n",
    "    xnew = np.linspace(min(x), max(x), num=50, endpoint=True)    \n",
    "    plt.plot(xnew, f(xnew), color='black', alpha=0.1)    \n",
    "    imp_ppr += [x]\n",
    "    imp_tpr += [y]\n",
    "\n",
    "all_ppr = np.unique(np.concatenate(imp_ppr))\n",
    "\n",
    "mean_tpr = np.zeros_like(all_ppr)\n",
    "for i in range(0, len(imp_ppr)):\n",
    "    mean_tpr += interp(all_ppr, imp_ppr[i], imp_tpr[i])\n",
    "mean_tpr /= len(imp_ppr)\n",
    "\n",
    "xnew = np.linspace(min(all_ppr), max(all_ppr), num=2 * len(all_ppr), endpoint=True)    \n",
    "f = interp1d(all_ppr, mean_tpr, kind='cubic')    \n",
    "plt.plot(xnew, f(xnew), color='red', alpha=1.0)\n",
    "\n",
    "fig.savefig(os.path.join(model_name, 'average-calibration-bootstrap.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
